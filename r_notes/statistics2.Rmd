---
title: "statistics"
output: 
  html_document:
    keep_md: true
    exclude: true
---

```{r, setup, echo = FALSE}
library(ggplot2)
# library(GGally)
data("mtcars")
# ggpairs(data = mtcars)

```

# Polynomial regression

```{r polynomial}
# linear first
m1 <- lm(wt ~ disp, data = mtcars)
m2 <- lm(wt ~ poly(disp, 2), data = mtcars)
m3 <- lm(wt ~ poly(disp, 3), data = mtcars)
anova(m1, m2)
anova(m2, m3)
anova(m1, m3)

p <- ggplot(data = mtcars, aes(x = disp, y = wt)) + 
  geom_smooth(method = "lm", formula = y ~ poly(x, 3)) + 
  geom_point()
p
```

# Quantile regression

# Ordinal regression

```{r ordinal}
# install.packages("ordinal")
library(ordinal)
data(wine)
head(wine)

m1 <- clm(rating ~ temp, data = wine)
m2 <- clm(rating ~ temp + contact, data = wine)

anova(m1, m2)
```

The anova above tests the null hypothesis that there is no difference in fit between the two models above. 
There is strong evidence against the null hypothesis and so it should be rejected. 

The summary gives the un-exponentiated coefficients for the two variables. 

```{r clm-summary}
summary(m2)
```

I think verbalising the interpretation of the summary output is not easy. 
Here's my understanding. 
A wine at baseline will have intercept odds of a rating. 
A wine that is warm will have an odds of a 
So, the odds of a wine being at the next level up (out of a 1-5 rating) increases by exp(2.5) [`r exp(coef(m2)[5])`] for warm wines compared to cold. 
