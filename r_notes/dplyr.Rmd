---
output:
  html_document:
    keep_md: true
    toc: true
    toc_float: true
    exclude: true
---

This needs a massive clean up. You may wish to disregard the information below. 
  
# dplyr and tidyr
  
dplyr introduces a consistent grammar of data manipulation for R. 
The significance of this should not be underestimated. 
It makes the standard data manipulation that all data analysts need to do so much easier. 
A particularly nice feature is the ability to connect a series of commands in the same way as pipes in Unix systems. 
Rather than the vertical bar `|`, the symbol is `%>%`.
The pipe takes input, commonly a dataframe from the left-hand side and passes it to functions on the right-hand side. 

As well as dplyr, Hadley has introduced another new package for reshaping: tidyr. 
Together with ggplot2, lubridate, stringr and others they form the 'tidyverse'.

* TOC
{:toc}

## The basics

dplyr has, as described in the introductory documentation, "five basic data manipulation verbs that work on a single table: filter(), arrange(), select(), mutate() and summarise()."

## Creating new variables

New variables are created using the `mutate()` verb, one takes a dataframe, passes it in a pipe to `mutate` and create a new variable in that function call.

```{r mutate}
library(dplyr)
library(stringr)
library(tidyr)

data("mtcars")

mtcars <- mtcars %>% 
  mutate(cyl_2 = cyl + 1, 
         mpg_2 = mpg * 2)

head(mtcars)
```

### Detecting strings

I have a vector in a dataframe and I wish to determine whether I can detect any one of a series of strings. 
I would normally use str_detect for this, but it doesn't work without a little trickery. 
The `paste(something, collapse = "|")` is the important bit here. 

```{r}
test_data <- data.frame(item = c("Apple", "Bear", "Orange", "Pear", "Two Apples"), 
                        stringsAsFactors = FALSE)
fruit <- c("Apple", "Orange", "Pear")
test_data

test_data <- test_data %>%  
  mutate(is.fruit = str_detect(item, paste(fruit, collapse = "|")))
test_data
```

### Replacing values with dplyr functions

Can use `recode()` or `case_when()`. 
`recode()` is a vectorised switch. 
It's important to note that the data types must be the same when using `recode()`, and that a double is not the same type as an integer, which seems obvious when typed. 
If they are not the same type, then unspecified replacements get NA values. 

```{r}
mtcars %>% 
  mutate(new_cyl = recode(cyl, `6` = 16, `8` = 200) ) %>% 
  select(cyl, new_cyl) %>% 
  tbl_df() %>%
  head()
```

`case_when()` vectorises multiple `if()` `else()` statements, and it's a lot neater than writing nested `ifelse()` statements. 
`case_when()` can be used inside a `mutate()` call, or outside.

There are times when the column needs to be specified with a `.$` in front but the situations in which this is required have changed as the package has developed.


```{r}

mtcars %>% 
mutate(
  new_cyl = case_when(cyl == 4 ~ "Four", 
                      cyl == 6 ~ "Six", 
                      cyl == 8 ~ "Eight"
                      )) %>%
  select(cyl, new_cyl) %>% 
  head()
```

There's an important gotcha here though. 
One has to make sure that each possible outcome is specified, otherwise unspecified levels are replaced with `<NA>` values.
One can work around this as in the second example. 
I haven't yet tested what will happen if numeric output is required, I expect that one would need `TRUE ~ as.double(.$cyl)`.
For numeric columns, it's also worth remembering that integer data types are not the same as other numeric data types such as doubles and so `as.numeric()` may still return `<NA>` values.

```{r}
mtcars %>% 
  mutate( cyl2 = case_when(
    cyl == 4 ~ "four"
  )
  ) %>% 
  select(cyl, cyl2) %>% 
  head()

mtcars %>% 
  mutate( cyl2 = case_when(
    cyl == 4 ~ "four", 
    TRUE ~ as.character(cyl)
  )
  ) %>% 
  select(cyl, cyl2) %>% 
  head()
```

This also works for detecting strings in columns. 
It's a bit weird giving the `TRUE ~ 0` for the non-true cases. 
I tried `FALSE ~ 0` and that doesn't work. 

```{r}
data(mtcars)
mtcars$name <- row.names(mtcars)
names_to_detect <- c("Mazda", "Datsun")

mtcars %>% 
  mutate(has_name = case_when(
    str_detect(name, paste(names_to_detect, collapse = "|")) == TRUE ~ 1, 
    TRUE ~ 0)
  )%>% 
  select(name, has_name) %>% 
  head()

```

## Working on multiple columns at once

`mutate_all` or `summarise_all` will affect all variables in the dataframe in the same way. 
`mutate_at` will mutate only the specified columns

```{r}
library("lubridate")
dat <- data.frame(x = c(1,2,3), 
  y_date = c("01/01/2017", "02/01/2017", "03/01/2017"), stringsAsFactors = FALSE)
dat <- dat %>% mutate_at(vars(contains("date")), funs(lubridate::dmy))
dat
```

summarise_at allows you to specify a set of columns one which to work.

```{r summarist-at}
data("mtcars")
mtcars %>% summarise_at(vars(mpg), funs(sum)) 

mtcars %>% summarise_at(vars(-mpg, - contains("cyl")), funs(sum))
mtcars %>% summarise_at(vars(matches("mpg")), funs(sum))

my_vars <- c("mpg", "cyl")
mtcars %>% summarise_at(vars(my_vars), funs(sum))
```

## Subsetting (aka filtering)

Much less verbose than `test[test$var1 == "something",]`
```{r, eval = FALSE}
filter(test, var1 == "something")
```
       
But getting unique combinations is a little more awkward. 
`group_by()` is covered a little later.

```{r}
test <- data.frame(id = c(1,1,1,2,2),
org = c("apple", "apple", "bear", "orange", "pear"),
test = c("S", "R","S", "R", "S"))
test

out <- test %>% group_by(id, org) %>% 
  filter(row_number() == 1)
out
```

## Summarising data

Uses the `summarise()` function. `n()` is a function introduced in dplyr and produces a count of the number of rows in the data set. 
                   
```{r}
library(binom)

test <- data.frame(group = c(rep("A", 10), rep("B", 10)),
outcome = c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0))
head(test)

table(test$group, test$outcome, dnn = c("Group", "Outcome"))

out <-test %>% group_by(group) %>% 
  summarise(n = n(), successes = sum(outcome)) %>% 
  mutate(pc.succ = round(binom.confint(successes, n, 
                                       methods = "exact")[[4]]*100, 2),
         pc.lci = round(binom.confint(successes, n, 
                                      methods = "exact")[[5]]*100, 2),
         pc.uci = round(binom.confint(successes, n, 
                                      methods = "exact")[[6]]*100, 2)
            )

out
```
                   
Outside dplyr I would write `binom.confint(x,n,methods = "exact")$mean`. 
This doesn't work in dplyr and returns the error `"Error in binom.confint(c(6928L, 5704L, 4746L, 5166L, 6779L, 6275L, 4832L,  : 
                                                                                                 invalid subscript type 'closure' "`
However, indexing the columns does work. 
Also, wrapping the `round()` and `binom.confint()` in a function would improve the readability of the process. 

### Passing arguments to `summarise_all`

For example, you might want to specify removal of NA values in a sum or mean function. 
You can do this by

```{r, eval = FALSE}
data(mtcars)
summarise_all(mtcars, funs(sum(., na.rm = TRUE)))
```                                                                                               
## Grouped operations

Grouping performs operations by levels of the grouping variable or variables. 
For example, I might want to get the mean mpg for each value of cylinder in mtcars:

```{r grouped}
mtcars %>% group_by(cyl) %>% 
  mutate(grouped_mpg = mean(mpg)) %>% 
  select(mpg, cyl, grouped_mpg) %>% 
  head()
```

### Adding a group id

Sometimes one might want to create an integer group id. 
i.e. for all rows with the same groupings, these will have the same id. 
`group_indices()` goes some of the way to resolve this by creating a vector of integers corresponding to the index numbers of the groups. 

Unfortunately, one can't use `group_indices()` in `mutate()`, it returns an error.
Therefore, one has to sort the dataframe by the grouping variables before adding in the id. 
It's important to note that the data **must** be sorted prior to the creation of `i`, otherwise the `mutate(group_id = i)` will be in the wrong sort order.

```{r}

data(mtcars)
mtcars <- mtcars %>% group_by(cyl, am) %>% arrange(cyl, am)

i <- mtcars %>% group_indices()

mtcars <- mtcars %>% ungroup() %>% mutate(group_id = i)
mtcars %>% select(cyl, am, group_id)

```

## Dropping and renaming variables

Variables can be renamed with `rename()`. 
The syntax is `rename(data, new.var = old.var)`. 
Note that there are no quotations marks. 
e.g. 

```{r}
rename(iris, petal_length = Petal.Length) %>% head()
```

Variables can be dropped using `select(data, -var_name)`. 
Or, if quicker, retained from a long list of variables, e.g. `select(data, var1, var2)`.
                                                                                               
```{r}
select(iris, -Sepal.Length) %>% head
```

```{r}
select(iris, Sepal.Length, Species) %>% head
```
                                                                                               
It's also possible to select columns based on text that the column name contains:
                                                                                               
```{r, eval = FALSE}
pps <- pps %>% select(p.full.id, contains("_atc"))
```
                                                                                               
thanks to: http://stackoverflow.com/questions/25923392/r-dplyr-select-columns-based-on-string

 
## Lagged values and windows
```{r}
#  test windowed functions
test <- data.frame(cbind(time = c(1:10), value = rep(1, 10)), 
                   stringsAsFactors = FALSE)
head(test)


test <- test %>% 
  mutate( lag1 = lag(value),
          lag2 = lag(value, 2),
          lag3 = lag(value, 3),
          lag4 = lag(value, 4)
          
          ) %>% # next line needs to be outside first mutate call otherwise it won't work.
  mutate(rolling_4 = rowSums(.[3:6], na.rm = TRUE))
test
```

## Wrapping dplyr in a function

Programming with dplyr has changed a lot with the release of dplyr 0.7. 
Previously there was a convoluted process using lazy eval and the `interp` function. 
Now, dplyr incorporates tidyeval and is much simpler. 
The vignette on [programming with dplyr](https://github.com/simonthelwall/simonthelwall.github.io.git) provides a much longer explanation of how it works.

### A simple tidyeval example
Say I want a function to sort a dataframe by a named column. 
I know that dplyr will already do this, but this is simply to illustrate how evaluation works when writing functions with dplyr. 

```{r}
data(mtcars)
select_a_column <- function(dat, column){
  col_to_use <- enquo(column)
  dat <- select(dat, !!col_to_use)
  return(dat)
}
select_a_column(mtcars, mpg) %>% head()
```

Two steps here: `enquo()` to capture the variable of interest and `!!` to use it. 

One has to interpret the multiple variables supplied, otherwise you get all sorts of errors. 
```{r}

# require(lazyeval) # I thought dplyr loaded this by default, but apparently not.
tabFun <- function(dat, y, z) {
  grouping_var <- enquo(y)
  summing_var <- enquo(z)
  a <- dat %>% group_by(!!grouping_var) %>%
    summarise(n = length(!!summing_var), 
              sum_z = sum(!!summing_var)) %>%
    mutate(pc = round((sum_z / n) * 100, 1)
           )
  return(a)
}
tabFun(mtcars, cyl, am)
```
Phew. 

Oh, and incidentally, trying to simplify this with n = n() returns the error `Error in n() : This function should not be called directly`. 

I don't know why. 

### Mutate in a function

```{r, eval=FALSE}

temp_dat <- data.frame(dob = as.Date("01/01/2017", format = "%d/%m/%Y"), 
                       sampledate = as.Date("15/06/2017", format = "%d/%m/%Y"))


age_fun <- function(dat, dob_var, sampledate_var) {
  var1 <- enquo(dob_var)
  var2 <- enquo(sampledate_var)
  out <- dat %>% 
    mutate(
      age = as.numeric( (!!var2) - (!!var1) ) / 365.25
    )
  return(out)
}

# doesn't work
age_fun2 <- function(dat, dob_var, sampledate_var) {
  # var1 <- enquo(dob_var)
  # var2 <- enquo(sampledate_var)
  out <- dat %>% 
    mutate(
      age = as.numeric( dob_var - sampledate_var ) / 365.25
    )
  return(out)
}

temp_dat <- age_fun(dat = temp_dat, dob_var = dob, sampledate_var = sampledate)
temp_dat <- age_fun2(dat = temp_dat, dob_var = dob, sampledate_var = sampledate)
temp_dat

```

## Joining

Very similar to plyr, but the function name specifies the type of join rather than specifying within the function. 

```{r, eval = FALSE}
                                                                                 data3 <- left_join(data1, data2, by = "common.var")

```
                                                                                 See [SQL Venn](https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/) for reminders. 

Usefully, one can join by more than one variable. 
This is useful when a single variable does not provide a unique identifier. 


```{r}
x <- data.frame(
  var1 = c(1, 1, 2),
  var2 = c("a", "b", "b"),
  var3 = c("x", "y", "z")
  )
y <- data.frame(var1 = c(1, 1, 2),
                var2 = c("a", "b", "b"),
                var4 = c(20, 21, 22)
                )
x
z <- left_join(x, y, by = c("var1", "var2"))
z
  
```

### anti_join

Anti join retains those records which are in the left table but not the right and retains the columns of the left table. 

This is probably more useful than one might at first think. 

```{r}
require(dplyr)

# want those in 2, that do not appear in 1
anti1 <- data.frame(id = c(1, 1, 1, 2, 3),
                    abx = c("pen", "amx", "flu", "pen", "amx"))
anti2 <- data.frame( id = c(1, 1, 1, 2, 4),
                     abx = c("pen", "amx", "flu", "flu", "pen"),
                     res = c("r", "i", "s", "i", "s")
                     )
anti1

anti2
anti3 <- anti_join(anti2, anti1, by = "id")
anti3

anti3 <- anti_join(anti2, anti1, by = c("id", "abx"))
anti3
```

## Hypothesis tests and dplyr

Technically possible, see broom and dplyr. 
I haven't (yet) managed this for a `chisq.test()` , but: 

```{r}
test <- as.data.frame(structure(
  list(organism.species.name = c("ec", "ec", "kp"),
       abx = c("ceph", "carb", "ceph"),
       n_sus_start = c(5L, 5L, 10L),
       n_res_start = c(10L, 5L, 5L),
       n_sus_end = c(10L, 5L, 5L),
       n_res_end = c(5L, 5L, 10L)),
  .Names = c("organism.species.name", "abx", "n_sus_start", "n_res_start",
  "n_sus_end", "n_res_end"), class = "data.frame", row.names = c(NA,-3L)
  ))
  
test %>% group_by(organism.species.name, abx) %>%
  mutate(p.val = chisq.test(matrix(
  c(n_sus_start, n_res_start, n_sus_end, n_res_end), nrow = 2))$p.value)
```
    
## tidyr

### wide to long
```{r}
stocks <-
  data.frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
  )
  stocks
  gather(data = stocks, key = stock, value = price, -time)

```

### long to wide

`spread()` takes long data and makes it wide. 
One specifies the `key` which contains the cells that will become column headers and then `value` column which contains the data that will go in the cells beneath the new columns.

```{r}
data(infert)
long <- infert %>%
  mutate(id = seq_along(education)) %>% # create integer id
  gather(key = variable, value = val,-id)

head(long)

long %>% spread(key = variable, value = val) %>%
  head()
```
                                                                                       
For a more complex approach see [this SO post](http://stackoverflow.com/questions/30592094/r-spreading-multiple-columns-with-tidyr#30592293).

See also `unite()` in tidyr

If `spread()` tells you `"Error: All columns must be named"`, then you have `NA` values in your key column. 

```{r}
dat <- data_frame(Person = rep(c("greg", "sally", "sue"), each = 2),
                  Time = rep(c("Pre", "Post"), 3),
                  Score1 = round(rnorm(6, mean = 80, sd = 4), 0),
                  Score2 = round(jitter(Score1, 15), 0),
                  Score3 = 5 + (Score1 + Score2) / 2)
  
head(dat)
  
dat %>%
  gather(temp, score, starts_with("Score")) %>%
  unite(temp1, Time, temp, sep = "_") %>%
  spread(temp1, score)
```

### Expanding data to cover all permutations

There are a number of options for this. 
A combination of spreading to wide, then gathering to long is one approach. 
However, tidyr also provides `complete` and `expand`. 
I quite often need to produce summary counts by an organisation and if one organisation hasn't reported any cases for a period then there will be a single `NA` row for that organisation, rather than multiple rows of zero. 

By the description in the manual, `complete` is 

> "a wrapper around expand(), dplyr::left_join() and replace_na() that’s useful for completing missing combinations of data"

Given the data below, I want to have all the rows for St James Infirmary that I also have for St Elsewhere. 

```{r complete-data-1}
dat <- structure(list(org_code = c("1A", "1A", "1A", "1A", "1A", "1A", 
                                   "1A", "1A", "1A", "1A", "1A", "1A", "2F"), 
                      status = c("FT", "FT", "FT", "FT", "FT", "FT", "FT", 
                                 "FT", "FT", "FT", "FT", "FT", "--"), 
                      org_name = c("St Elsewhere", "St Elsewhere", "St Elsewhere", 
                                   "St Elsewhere", "St Elsewhere", "St Elsewhere", 
                                   "St Elsewhere", "St Elsewhere", "St Elsewhere", 
                                   "St Elsewhere", "St Elsewhere", "St Elsewhere", 
                                   "St James Infirmary"), 
                      year = c(2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2017L, 
                               2017L, 2017L, 2017L, 2017L, 2017L, NA), 
                      month = c(11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 2L, 
                                2L, 2L, NA), 
                      measure = c("measure_a", "measure_b", "measure_c", 
                                  "measure_a", "measure_b", "measure_c", 
                                  "measure_a", "measure_b", "measure_c", 
                                  "measure_a", "measure_b", "measure_c", NA), 
                      count = c(1L, 5L, 7L, 5L, 9L, 3L, 7L, 4L, 2L, 9L, 5L, 7L, 
                                NA)), .Names = c("org_code", "status", 
                                                 "org_name", "year", "month", 
                                                 "measure", "count"), 
                 class = "data.frame", row.names = c(NA, -13L))

dat
```

Using `complete` I get what I need. 
I also need to use `unite` and `separate`, otherwise I get rows for 2016 month 1 and 2016 month 2.

```{r complete-data-2}
dat2 <- dat %>% 
  unite(year_month, year, month) %>% 
  complete(year_month, measure, 
                         nesting(org_code, status, org_name), 
                        fill = list(count = 0)) %>% 
  separate(year_month, into = c("year", "month")) %>%
  # don't strictly need these lines, but they make the result more logical based on original data
  select(org_code, status, org_name, year, month, measure) %>% # re-order cols
  arrange(org_code, year, month, measure) # sort data
tail(dat2, n = 12)
```

The manual adds a helpfull explanation of the use of `nesting`:

> "To find all unique combinations of x, y and z, including those not found in the data, supply each variable as a separate argument. To find only the combinations that occur in the data, use nest: expand(df, nesting(x, y, z))."

Crossing is the tidy equivalent of expand.grid and doesn't convert strings to factors.

```{r crossing}
crossing(year = c(2016, 2017, 2018), 
         month = c("January", "February", "March"))
```